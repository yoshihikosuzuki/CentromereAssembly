import logging
import logzero
from logzero import logger
import pandas as pd
from .peak import PeaksFinder
from BITS.utils import save_pickle


def main():
    args = load_args()

    # Detect peak unit lenghs
    pf = PeaksFinder(args.reads_fname, args.units_fname)
    pf.run()

    # For each peak, calculate representative units
    repr_units = pd.DataFrame()
    for i, peak in enumerate(pf.peaks):
        #if i != len(pf.peaks) - 1:   # only the last peak   # NOTE: for debug
        #    continue

        logger.info(f"Start peak {i}")
        peak.calc_repr_units(args.min_n_units, args.n_core)

        # Add "peak_id" and "repr_id" columns
        repr_units = pd.concat([repr_units,
                                peak.master_units.assign(peak_id=i) \
                                                 .assign(repr_id=range(peak.master_units.shape[0]))])

    # Save representative units and intermediate data on peaks
    repr_units.reset_index(drop=True) \
              .reindex(columns=("peak_id",
                                "repr_id",
                                "cluster_id",
                                "cluster_size",
                                "length",
                                "sequence")) \
              .set_index(["peak_id", "repr_id"]) \
              .to_csv(args.out_repr_fname, sep='\t')
    save_pickle(pf, args.out_pkl_fname)
    pf.reads.to_csv("tr_reads", sep='\t')


def load_args():
    import argparse
    parser = argparse.ArgumentParser(
        description=("Determine representative units based on global sequence similarity."))

    parser.add_argument(
        "-r",
        "--reads_fname",
        type=str,
        default="reads.fasta",
        help=("A file of the raw reads. [reads.fasta]"))

    parser.add_argument(
        "-u",
        "--units_fname",
        type=str,
        default="datruf_units",
        help=("A file of the unit sequences generated by datruf. [datruf_units]"))

    parser.add_argument(
        "-o",
        "--out_repr_fname",
        type=str,
        default="repr_units",
        help=("Output representative units file. [repr_units]"))

    parser.add_argument(
        "-p",
        "--out_pkl_fname",
        type=str,
        default="peaks_finder.pkl",
        help=("Output pickle file of PeaksFinder object. [peaks_finder.pkl]"))

    parser.add_argument(
        "-m",
        "--min_n_units",
        type=int,
        default=10,
        help=("Minimum number of units in a single TR whose consensus will be taken. [10]"))

    parser.add_argument(
        "-n",
        "--n_core",
        type=int,
        default=1,
        help=("Degree of parallelization. [1]"))

    parser.add_argument(
        "-D",
        "--debug_mode",
        action="store_true",
        default=False,
        help=("Run in debug mode. [False]"))

    args = parser.parse_args()
    if args.debug_mode:
        logzero.loglevel(logging.DEBUG)
        pd.set_option('expand_frame_repr', False)   # show entire dataframe
    else:
        logzero.loglevel(logging.INFO)
    del args.debug_mode

    return args


if __name__ == "__main__":
    main()
